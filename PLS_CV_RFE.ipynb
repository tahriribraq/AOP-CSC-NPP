{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for running PLS using 1 up to n_comp components and returning the number of components which yielded the highest CV $R^{2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_pls_cv(X, y, n_comp, cv_f, plot_components=True):\n",
    " \n",
    "    '''Run PLS including a variable number of components, up to n_comp,\n",
    "       and calculate MSE '''\n",
    " \n",
    "    r2, mse = [], []\n",
    "    if X.shape[1] < n_comp: # if features are less than maximum number of components\n",
    "        if X.shape[1] == 1: # when 1 feature left, use 1 component \n",
    "            component = [1]\n",
    "        else:\n",
    "            component = np.arange(1, X.shape[1]) # max components are 1 less than total features\n",
    "    else:\n",
    "        component = np.arange(1, n_comp)\n",
    " \n",
    "    for i in component:\n",
    "        pls = PLSRegression(n_components=i)\n",
    "        # Cross-validation\n",
    "        y_cv = cross_val_predict(pls, X, y, cv=cv_f)\n",
    "        mse.append(mean_squared_error(y, y_cv))\n",
    "        r2.append(r2_score(y, y_cv))\n",
    " \n",
    "    # Calculate and print the position of minimum in MSE\n",
    "    if not mse:\n",
    "        msemin = 0\n",
    "    else:\n",
    "        msemin = np.argmin(mse)\n",
    "    if not r2:\n",
    "        r2max = r2_score(y, y_cv)\n",
    "    else:\n",
    "        r2max = np.argmax(r2)\n",
    " \n",
    "    if plot_components is True:\n",
    "        with plt.style.context(('ggplot')):\n",
    "            plt.plot(component, np.array(r2), '-v', color = 'blue', mfc='blue')\n",
    "            plt.plot(component[r2max], np.array(r2)[r2max], 'P', ms=10, mfc='red')\n",
    "            plt.xlabel('Number of PLS components')\n",
    "            plt.ylabel('R-Sq')\n",
    "            plt.title('PLS')\n",
    "            plt.xlim(left=-1)\n",
    " \n",
    "        plt.show()\n",
    " \n",
    "    return r2max+1, np.max(r2), np.min(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for running PLS using optimal number of components and RFE to identify the best-performing CSC-NPP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_rfe_cv(X_df, X, y, max_comp, cv_fold):\n",
    "    r2_cv, mse_fit = np.zeros(X.shape[1]), np.zeros(X.shape[1]) # store CV r2 and mse from max number of features to 1\n",
    "    r2_fit, mse_cv = np.zeros(X.shape[1]), np.zeros(X.shape[1]) # store r2 and mse of fitting data from max number of features to 1\n",
    "    metrics_det = list(X_df.columns[2:]) # initiate with all metric names\n",
    "    metrics_sub = np.empty(X.shape[1], dtype=object) # store list of included metrics after each elimination\n",
    "    metrics_sub[-1] = metrics_det # append full set of metrics as last element\n",
    "    coeffs = np.empty(X.shape[1], dtype=object) # store coefficients of included metrics after each elimination\n",
    "    r2_best, n_comp_best = 0, 0 # store r2 score and number of components selected in best model\n",
    "\n",
    "    # Recursively eliminate least important features until 1 is left\n",
    "    for i in reversed(range(0, len(r2_cv))):\n",
    "        # Find optimal number of components\n",
    "        n_comps, r2_max, mse_min = optimise_pls_cv(X, y, max_comp, cv_fold, plot_components=False)\n",
    "        print(f\"Number of components selected with {i+1} features:\", n_comps)\n",
    "        if r2_max > r2_best: # Store number of components of best model (highest CV r2 score)\n",
    "            r2_best = r2_max\n",
    "            n_comp_best = n_comps\n",
    "        r2_cv[i] = r2_max # store cross-validation max r2\n",
    "        mse_cv[i] = mse_min # store cross-validation min mse\n",
    "        # Fit the model to the training data\n",
    "        pls = PLSRegression(n_components=n_comps)\n",
    "        pls.fit(X, y)\n",
    "        coeffs[i] = list(pls.coef_.reshape(-1)) # Store included coefficients after elimination\n",
    "        y_est = pls.predict(X)\n",
    "        r2 = r2_score(y, y_est)\n",
    "        mse = mean_squared_error(y, y_est)\n",
    "        r2_fit[i] = r2 # store r2 score with training set\n",
    "        mse_fit[i] = mse # store mse with training set\n",
    "        # Eliminate least important feature (lowest absolute coefficient)\n",
    "        el_ind = np.argmin(np.absolute(pls.coef_)) # index of lowest coefficient\n",
    "        metrics_det = np.delete(metrics_det, el_ind) # delete least important metric name \n",
    "        if i>0:\n",
    "            metrics_sub[i-1] = metrics_det # Store included metrics after elimination\n",
    "        X = np.delete(X, el_ind, axis=1) # delete least important column for next iteration\n",
    "\n",
    "    # Return list of CV values, Fit values, included metrics, included coefficients, and # of components of best model\n",
    "    return r2_cv, mse_cv, r2_fit, mse_fit, metrics_sub, coeffs, n_comp_best"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
